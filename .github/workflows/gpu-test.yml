name: GPU Tests (CUDA)

on:
  pull_request:
    branches: [ main ]
    paths:
      - 'liblloyal'
      - 'llama.cpp'
      - 'lib/**'
      - 'src/**'
      - 'test/**'
      - 'CMakeLists.txt'
  workflow_dispatch:

jobs:
  build-cuda-package:
    name: Build linux-x64-cuda
    if: ${{ github.repository == 'lloyal-ai/lloyal.node' }}
    runs-on: ubuntu-22.04

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 24
          registry-url: 'https://registry.npmjs.org'

      - name: Validate llama.cpp version
        run: node scripts/sync-llama-cpp.js --check
        shell: bash

      # CUDA 12.2.2 required for Cloud Run L4 GPU (driver 535.x)
      # provision-cuda also installs build-essential + cmake
      - name: Provision CUDA toolkit
        uses: ./.github/actions/provision-cuda
        with:
          version: '12.2.2'
          arch: x64

      - name: Setup ccache
        uses: hendrikmuhs/ccache-action@v1.2
        with:
          key: cuda-build-${{ runner.os }}

      - name: Install npm dependencies
        run: npm ci --ignore-scripts

      - name: Build native module
        run: npm run build
        env:
          LLOYAL_GPU: cuda
          CMAKE_C_COMPILER_LAUNCHER: ccache
          CMAKE_CXX_COMPILER_LAUNCHER: ccache
          CMAKE_CUDA_COMPILER_LAUNCHER: ccache

      - name: Create platform package
        run: node scripts/create-platform-package.js linux-x64-cuda ubuntu-22.04 x64

      - name: Upload platform package artifact
        uses: actions/upload-artifact@v4
        with:
          name: package-linux-x64-cuda
          path: packages/linux-x64-cuda/
          retention-days: 1
          compression-level: 0

  # GPU Integration Tests via Cloud Run (L4)
  # Infrastructure details are in the private lloyal-infra repo
  gpu-integration:
    name: GPU Tests (L4)
    needs: build-cuda-package
    if: ${{ github.repository == 'lloyal-ai/lloyal.node' && needs.build-cuda-package.result == 'success' }}
    uses: lloyal-ai/lloyal-infra/.github/workflows/gpu-integration.yml@main
    secrets: inherit
    permissions:
      contents: read
      id-token: write
