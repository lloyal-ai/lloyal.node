# GPU Testing Image for lloyal.node (CUDA only)
# Runs integration tests on NVIDIA L4 GPU via Cloud Run Jobs
#
# Note: Vulkan is tested separately on GitHub Actions with software rendering
# because Cloud Run only mounts CUDA libs, not Vulkan/graphics driver components.
#
# Build: docker build -f ci/Dockerfile.gpu-tests -t gpu-tests .
# Run:   docker run --gpus all gpu-tests

# CUDA 12.2.2 required for Cloud Run L4 GPU (driver 535.x supports up to 12.2.x)
FROM nvidia/cuda:12.2.2-runtime-ubuntu22.04

# Install runtime dependencies
# - libgomp1: OpenMP runtime (required by llama.cpp CUDA build)
RUN apt-get update && apt-get install -y --no-install-recommends \
    wget \
    curl \
    ca-certificates \
    jq \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Install Node.js 24
RUN wget -qO- https://deb.nodesource.com/setup_24.x | bash - \
    && apt-get install -y nodejs \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy package.json first for dependency caching
COPY package.json ./

# Install dependencies (omit dev deps - only need runtime deps like @lloyal-labs/tsampler)
RUN npm install --omit=dev

# Copy pre-built packages from release workflow
# These are downloaded as artifacts before docker build
COPY packages/ ./packages/

# Copy test files, examples, lib, and scripts
COPY test/ ./test/
COPY examples/ ./examples/
COPY lib/ ./lib/
COPY scripts/download-test-models.sh ./scripts/

# Models downloaded at runtime via run-gpu-tests.sh
# This allows testing multiple models from test/matrix.json
# without baking large files into the image

# Test script
COPY ci/run-gpu-tests.sh ./

ENTRYPOINT ["bash", "run-gpu-tests.sh"]
